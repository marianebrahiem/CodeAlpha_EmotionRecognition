# CodeAlpha_EmotionRecognition
# Emotion Recognition from Speech üéôÔ∏è  

This project is part of my **CodeAlpha Cybersecurity Internship**, focused on recognizing human emotions (e.g., Happy, Angry, Sad) from speech audio files using **deep learning** and **speech signal processing**.

# Features  
- Extracts **MFCC (Mel-Frequency Cepstral Coefficients)** features from `.wav` audio files.  
- Uses an **LSTM-based neural network** to classify emotions.  
- Supports multiple emotion classes: Neutral, Happy, Sad, Angry, Fearful.  
- Provides training accuracy, validation accuracy, and a confusion matrix for evaluation.  

##Tech Stack  
- Python  
- **Librosa** (audio processing)  
- **NumPy, Pandas** (data handling)  
- **Keras (TensorFlow)** (deep learning model)  
- **Matplotlib** (accuracy visualization)  
- **Scikit-learn** (encoding labels, train-test split)  

   
